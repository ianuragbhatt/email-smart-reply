{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport string, os \nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:21.961312Z","iopub.execute_input":"2022-05-10T07:55:21.961703Z","iopub.status.idle":"2022-05-10T07:55:26.423471Z","shell.execute_reply.started":"2022-05-10T07:55:21.961625Z","shell.execute_reply":"2022-05-10T07:55:26.422635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:26.425372Z","iopub.execute_input":"2022-05-10T07:55:26.42569Z","iopub.status.idle":"2022-05-10T07:55:26.438065Z","shell.execute_reply.started":"2022-05-10T07:55:26.425656Z","shell.execute_reply":"2022-05-10T07:55:26.437116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 200  # Number of epochs to train for.\nlatent_dim = 512  # Latent dimensionality of the encoding space.\nnum_samples = 50000","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:26.440042Z","iopub.execute_input":"2022-05-10T07:55:26.440631Z","iopub.status.idle":"2022-05-10T07:55:26.445019Z","shell.execute_reply.started":"2022-05-10T07:55:26.440595Z","shell.execute_reply":"2022-05-10T07:55:26.44392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading dataset\ndf = pd.read_csv('../input/chatbot-dataset-topical-chat/topical_chat.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:26.446617Z","iopub.execute_input":"2022-05-10T07:55:26.44732Z","iopub.status.idle":"2022-05-10T07:55:26.933295Z","shell.execute_reply.started":"2022-05-10T07:55:26.447281Z","shell.execute_reply":"2022-05-10T07:55:26.932359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic preprocessing\ndef process(text):\n    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n          .replace('\"', ' ').replace(\".\", \" \").replace(\"!\", \" \").replace(\"?\", \" \").replace(\";\", \" \").replace(\":\", \" \")\n\n    text = \"\".join(v for v in text if v not in string.punctuation).lower()\n    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n\n    text = \" \".join(text.split())\n    #text+=\"<eos>\"\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:26.935552Z","iopub.execute_input":"2022-05-10T07:55:26.935942Z","iopub.status.idle":"2022-05-10T07:55:26.942104Z","shell.execute_reply.started":"2022-05-10T07:55:26.935903Z","shell.execute_reply":"2022-05-10T07:55:26.941241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.message = df.message.apply(process)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:26.94401Z","iopub.execute_input":"2022-05-10T07:55:26.944374Z","iopub.status.idle":"2022-05-10T07:55:30.434694Z","shell.execute_reply.started":"2022-05-10T07:55:26.944338Z","shell.execute_reply":"2022-05-10T07:55:30.433802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:30.436094Z","iopub.execute_input":"2022-05-10T07:55:30.436449Z","iopub.status.idle":"2022-05-10T07:55:30.447169Z","shell.execute_reply.started":"2022-05-10T07:55:30.436414Z","shell.execute_reply":"2022-05-10T07:55:30.446162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_words_set = set()\ntarget_words_set = set()\n\nfor conversation_index in tqdm(range(df.shape[0])):\n    \n    if conversation_index == 0:\n        continue\n        \n    input_text = df.iloc[conversation_index - 1]\n    target_text = df.iloc[conversation_index]\n    \n    if input_text.conversation_id == target_text.conversation_id:\n        \n        input_text = input_text.message\n        target_text = target_text.message\n        \n        if len(input_text.split()) > 2 and \\\n            len(target_text.split()) > 0 and \\\n            len(input_text.split()) < 30 and \\\n            len(target_text.split()) < 10 and \\\n            input_text and \\\n            target_text:\n            \n            target_text = \"bos \" + target_text + \" eos\"\n                \n            input_texts.append(input_text)\n            target_texts.append(target_text)\n            \n            for word in input_text.split():\n                if word not in input_words_set:\n                    input_words_set.add(word)\n            for word in target_text.split():\n                if word not in target_words_set:\n                    target_words_set.add(word)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:55:30.449883Z","iopub.execute_input":"2022-05-10T07:55:30.450735Z","iopub.status.idle":"2022-05-10T07:56:25.925028Z","shell.execute_reply.started":"2022-05-10T07:55:30.450698Z","shell.execute_reply":"2022-05-10T07:56:25.923748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_words = sorted(list(input_words_set))\ntarget_words = sorted(list(target_words_set))\nnum_encoder_tokens = len(input_words)\nnum_decoder_tokens = len(target_words)\nmax_encoder_seq_length = max([len(txt.split()) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt.split()) for txt in target_texts])\n\nprint(\"Number of samples:\", len(input_texts))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)\n\ninput_token_index = dict([(word, i) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i) for i, word in enumerate(target_words)])\n\n#saving\nwith open('input_token_index.pickle', 'wb') as handle:\n    pickle.dump(input_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n#saving\nwith open('target_token_index.pickle', 'wb') as handle:\n    pickle.dump(target_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n)\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n)\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n)\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    \n    for t, word in enumerate(input_text.split()):\n        encoder_input_data[i, t] = input_token_index[word]\n    \n    for t, word in enumerate(target_text.split()):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t] = target_token_index[word]\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[word]] = 1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:56:25.927005Z","iopub.execute_input":"2022-05-10T07:56:25.927303Z","iopub.status.idle":"2022-05-10T07:56:26.835671Z","shell.execute_reply.started":"2022-05-10T07:56:25.92726Z","shell.execute_reply":"2022-05-10T07:56:26.834658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_size = 100\n\n# seq2seq model - https://keras.io/examples/nlp/lstm_seq2seq/\nwith strategy.scope():\n    # Define an input sequence and process it.\n    encoder_inputs = keras.Input(shape=(None,))\n    \n    encoder_embedding_output = keras.layers.Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n                                               \n    encoder = keras.layers.LSTM(latent_dim, return_state=True)\n    encoder_outputs, state_h, state_c = encoder(encoder_embedding_output)\n\n    # We discard `encoder_outputs` and only keep the states.\n    encoder_states = [state_h, state_c]\n\n    # Set up the decoder, using `encoder_states` as initial state.\n    decoder_inputs = keras.Input(shape=(None,))\n    \n    decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size)\n    decoder_embedding_output = decoder_embedding(decoder_inputs)\n    \n\n    # We set up our decoder to return full output sequences,\n    # and to return internal states as well. We don't use the\n    # return states in the training model, but we will use them in inference.\n    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n    decoder_outputs, _, _ = decoder_lstm(decoder_embedding_output, initial_state=encoder_states)\n    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n    decoder_outputs = decoder_dense(decoder_outputs)\n\n    # Define the model that will turn\n    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n    model.compile(\n        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n    )\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:56:26.840405Z","iopub.execute_input":"2022-05-10T07:56:26.842604Z","iopub.status.idle":"2022-05-10T07:56:30.020924Z","shell.execute_reply.started":"2022-05-10T07:56:26.842561Z","shell.execute_reply":"2022-05-10T07:56:30.020131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=batch_size,\n    epochs=20,\n    validation_split=0.1,\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-10T07:56:30.024137Z","iopub.execute_input":"2022-05-10T07:56:30.024411Z","iopub.status.idle":"2022-05-10T08:02:44.009778Z","shell.execute_reply.started":"2022-05-10T07:56:30.024384Z","shell.execute_reply":"2022-05-10T08:02:44.00885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.012651Z","iopub.execute_input":"2022-05-10T08:02:44.012911Z","iopub.status.idle":"2022-05-10T08:02:44.210547Z","shell.execute_reply.started":"2022-05-10T08:02:44.012885Z","shell.execute_reply":"2022-05-10T08:02:44.209565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nmodel.save(\"s2s.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.211686Z","iopub.execute_input":"2022-05-10T08:02:44.212008Z","iopub.status.idle":"2022-05-10T08:02:44.394398Z","shell.execute_reply.started":"2022-05-10T08:02:44.211971Z","shell.execute_reply":"2022-05-10T08:02:44.393614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the encoder model \nencoder_model = keras.Model(encoder_inputs, encoder_states)\nencoder_model.summary()\n\ndecoder_state_input_h = keras.Input(shape=(None,))\ndecoder_state_input_c = keras.Input(shape=(None,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndecoder_embedding_output = decoder_embedding(decoder_inputs)\n\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding_output, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2)\ndecoder_model = keras.Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n# Reverse-lookup token index to decode sequences back \nreverse_input_char_index = dict(\n    (i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict(\n    (i, char) for char, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.397653Z","iopub.execute_input":"2022-05-10T08:02:44.397916Z","iopub.status.idle":"2022-05-10T08:02:44.614198Z","shell.execute_reply.started":"2022-05-10T08:02:44.39789Z","shell.execute_reply":"2022-05-10T08:02:44.613345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_model.save(\"encoder_model.hdf5\")\ndecoder_model.save(\"decoder_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.617262Z","iopub.execute_input":"2022-05-10T08:02:44.617557Z","iopub.status.idle":"2022-05-10T08:02:44.691124Z","shell.execute_reply.started":"2022-05-10T08:02:44.617524Z","shell.execute_reply":"2022-05-10T08:02:44.690337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def respond(text):\n    input_seq = np.zeros(\n        (1, max_encoder_seq_length), dtype=\"float32\"\n    )\n    \n    for t, word in enumerate(text.split()):\n        input_seq[0, t] = input_token_index[word]\n        \n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['bos']\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        \n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == 'eos' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n        else:\n            decoded_sentence += ' ' + sampled_char\n            \n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        # Update states\n        states_value = [h, c]\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.692924Z","iopub.execute_input":"2022-05-10T08:02:44.693425Z","iopub.status.idle":"2022-05-10T08:02:44.70316Z","shell.execute_reply.started":"2022-05-10T08:02:44.693387Z","shell.execute_reply":"2022-05-10T08:02:44.70234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"respond(\"how are you\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:44.704904Z","iopub.execute_input":"2022-05-10T08:02:44.705458Z","iopub.status.idle":"2022-05-10T08:02:45.574953Z","shell.execute_reply.started":"2022-05-10T08:02:44.705417Z","shell.execute_reply":"2022-05-10T08:02:45.574265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"respond(\"good morning\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:45.57608Z","iopub.execute_input":"2022-05-10T08:02:45.576421Z","iopub.status.idle":"2022-05-10T08:02:45.849755Z","shell.execute_reply.started":"2022-05-10T08:02:45.576386Z","shell.execute_reply":"2022-05-10T08:02:45.849021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"respond(\"good bye\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:45.850912Z","iopub.execute_input":"2022-05-10T08:02:45.851233Z","iopub.status.idle":"2022-05-10T08:02:45.967106Z","shell.execute_reply.started":"2022-05-10T08:02:45.851195Z","shell.execute_reply":"2022-05-10T08:02:45.966361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for seq_index in range(20):\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    decoded_sentence = respond(input_texts[seq_index])\n    print(\"-\")\n    print(\"Input sentence:\", input_texts[seq_index])\n    print(\"Decoded sentence:\", decoded_sentence)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:45.968445Z","iopub.execute_input":"2022-05-10T08:02:45.968757Z","iopub.status.idle":"2022-05-10T08:02:52.853383Z","shell.execute_reply.started":"2022-05-10T08:02:45.96872Z","shell.execute_reply":"2022-05-10T08:02:52.852373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eos_token = target_token_index['eos']\neos_token","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:52.854742Z","iopub.execute_input":"2022-05-10T08:02:52.855094Z","iopub.status.idle":"2022-05-10T08:02:52.861697Z","shell.execute_reply.started":"2022-05-10T08:02:52.855056Z","shell.execute_reply":"2022-05-10T08:02:52.860752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import log\ndef generate_beam_text(seed_text, next_words, beam_search_n, break_at_eos):\n    \n    distributions_scores_states = [[list(), 0.0, [None, None]]]\n    \n    decoder_states_value = None\n    \n    for _ in range(next_words):\n        \n        sequence_temp_candidates = list()\n        \n        for i in range(len(distributions_scores_states)): \n            \n            input_seq = np.zeros(\n                (1, max_encoder_seq_length), dtype=\"float32\"\n            )\n            \n            # Generate empty target sequence of length 1.\n            target_seq = np.zeros((1,1))\n            \n            seq, score, states_values = distributions_scores_states[i]\n            \n            if len(distributions_scores_states) == 1:\n                for t, word in enumerate(process(seed_text).split()):\n                    input_seq[0, t] = input_token_index[word]\n                \n                # Encode the input as state vectors.\n                decoder_states_value = encoder_model.predict(input_seq)\n                \n                # Populate the first character of target sequence with the start character.\n                target_seq[0, 0] = target_token_index['bos']\n                \n            else:\n                target_seq[0, 0] = seq[-1]\n                decoder_states_value = states_values\n                \n                candidate_sentence = \"\"\n                for token_index in seq:\n                    if token_index == eos_token:\n                        break\n                        \n                    word = reverse_target_char_index[token_index]\n                    candidate_sentence+=word + \" \"\n                \n                print(\"score :\", score, \" | \", candidate_sentence)\n            \n            \n            output_tokens_distribution, h, c = decoder_model.predict([target_seq] + decoder_states_value)\n            \n            # Update states\n            decoder_states_value = [h, c]\n\n            predicted_distribution = output_tokens_distribution[0][0]\n            \n            for j in range(len(predicted_distribution)):\n                if predicted_distribution[j] > 0:\n                    candidate = [seq + [j], score - log(predicted_distribution[j]), decoder_states_value]\n                    if break_at_eos and j == eos_token:\n                        continue\n                    else:\n                        sequence_temp_candidates.append(candidate)\n\n        \n        # 2. score and sort all candidates\n        ordered = sorted(sequence_temp_candidates, key=lambda tup:tup[1])\n        \n        distributions_scores_states = ordered[:beam_search_n]\n          \n        print(\"-----\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:52.863154Z","iopub.execute_input":"2022-05-10T08:02:52.863719Z","iopub.status.idle":"2022-05-10T08:02:52.877276Z","shell.execute_reply.started":"2022-05-10T08:02:52.86368Z","shell.execute_reply":"2022-05-10T08:02:52.876422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_beam_text(\"i wonder if they met how that would go from there\", 5, 5, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:52.878469Z","iopub.execute_input":"2022-05-10T08:02:52.878857Z","iopub.status.idle":"2022-05-10T08:02:55.95103Z","shell.execute_reply.started":"2022-05-10T08:02:52.878812Z","shell.execute_reply":"2022-05-10T08:02:55.949992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_beam_text(\"do you like comic books\", 4, 5, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:02:55.952474Z","iopub.execute_input":"2022-05-10T08:02:55.953043Z","iopub.status.idle":"2022-05-10T08:02:57.503207Z","shell.execute_reply.started":"2022-05-10T08:02:55.952989Z","shell.execute_reply":"2022-05-10T08:02:57.501805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_beam_text(\"thanks\", 5, 5, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:03:57.220269Z","iopub.execute_input":"2022-05-10T08:03:57.220651Z","iopub.status.idle":"2022-05-10T08:03:59.925164Z","shell.execute_reply.started":"2022-05-10T08:03:57.220617Z","shell.execute_reply":"2022-05-10T08:03:59.924271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_beam_text(\"hi do you like to dance\", 5, 5, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:03:59.982615Z","iopub.execute_input":"2022-05-10T08:03:59.985045Z","iopub.status.idle":"2022-05-10T08:04:02.369047Z","shell.execute_reply.started":"2022-05-10T08:03:59.985002Z","shell.execute_reply":"2022-05-10T08:04:02.36773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_beam_text(\"hello how are you\", 5, 5, False)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:04:49.031825Z","iopub.execute_input":"2022-05-10T08:04:49.03216Z","iopub.status.idle":"2022-05-10T08:04:51.204532Z","shell.execute_reply.started":"2022-05-10T08:04:49.032128Z","shell.execute_reply":"2022-05-10T08:04:51.203578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}